Studying Facebook via Data Extraction: The Netvizz
Application
Bernhard Rieder
University of Amsterdam
Turfdraagsterpad 9
1012TX Amsterdam
rieder@uva.nl
ABSTRACT
This paper describes Netvizz, a data collection and
extraction application that allows researchers to export data
in standard file formats from different sections of the
Facebook social networking service. Friendship networks,
groups, and pages can thus be analyzed quantitatively and
qualitatively with regards to demographical, postdemographical, and relational characteristics. The paper
provides an overview over analytical directions opened up
by the data made available, discusses platform specific
aspects of data extraction via the official Application
Programming Interface, and briefly engages the difficult
ethical considerations attached to this type of research.
Author Keywords
research tool, social networking services, Facebook, data
extraction, social network analysis, media studies
ACM Classification Keywords
J.4 Social and Behavioral Sciences
INTRODUCTION
In October 2012, Facebook announced that it had reached
the symbolic number of one billion monthly active users.
[4] This arguably makes it one of the biggest media
organizations in the history of humankind, contested only
by Google’s collection of services in terms of daily
worldwide audience size and engagement. Traditional
corporations dwarf these massive Internet companies when
it comes to the size of their workforce – Facebook
employed a mere 4500 people at the end of 2012 – but the
sheer number of “[p]eople [who] use Facebook to stay
connected with friends and family, to discover what’s going
on in the world, and to share and express what matters to
them” [4] is simply gigantic. It is no wonder, then, that
researchers from many areas of the human and social
sciences have moved quickly to study the platform: a recent
review article [19] identified 412 peer-reviewed research
papers that follow empirical approaches, not counting the
numerous publications employing conceptual and/or critical
approaches. While traditional empirical methods such as
interviews, experiments, and observations are widely used,
a growing number of studies rely on what the authors call
“data crawling”, i.e. “gleaning information about users from
their profiles without their active participation” [19]. This
paper presents a software tool, Netvizz, designed to
facilitate this latter approach.
Research methods using software to capture, produce, or
repurpose digital data in order to investigate different
aspects of the Internet have been used for well over a
decade. Datasets can be exploited to analyze complex social
and cultural phenomena and digital methods [12] have a
number of advantages compared to traditional ones:
advantages concerning cost, speed, exhaustiveness, detail,
and so forth, but also related to the rich contextualization
afforded by the close association between data and the
properties of the media (technologies, platforms, tools,
websites, etc.) they are connected with; data crawling
necessarily engages these media through the specifics of
their technical and functional structure and therefore
produces data that can provide detailed views of the
systems and the use practices they host. The study of social
networking services (SNS) like Facebook, however,
introduces a number of challenges and considerations that
makes the scholarly investigation of these services, their
users, and the various forms of content they hold
significantly different from the study of the open Web. This
paper discusses some of the possibilities and difficulties
with the data crawling approach applied to Facebook and
introduces a tool that allows researchers to generate data
files in standard formats for different sections of the
Facebook social networking service without having to
resort to manual collecting or custom programming. I will
first introduce some of the approaches to data extraction on
SNS, in order to situate the proposed tool. I will then
introduce the Netvizz application and provide a number of
short examples for the type of analysis it makes possible.
Before concluding, I will discuss two further aspects that
are particularly relevant to the matter at hand: research via
Application Programming Interfaces (API) and the question
of privacy and research ethics. While this paper contains
technical descriptions, it is written from a media studies
perspective and therefore focuses on aspects most relevant
to media scholars.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise,
or republish, to post on servers or to redistribute to lists, requires prior
specific permission and/or a fee.
WebSci’13, May 2–4, 2013, Paris, France.
Copyright 2013 ACM 978-1-4503-1889-1....$10.00.
STUDYING FACEBOOK THROUGH DATA EXTRACTION
The study of Internet platforms via data extraction has seen
fast growth over the last two decades and the recent
excitement around the concept of big data seems to have
added additional momentum to efforts going into this
direction. [9] For researchers from the humanities and
social sciences, the possibility to analyze the expressions
and behavioral traces from sometimes very large numbers
of individuals or groups using these platforms can provide
valuable insights into the arrays of meaning and practice
that emerge and manifest themselves online. Besides
merely shedding light on a “virtual” space, supposedly
separate from “real life”, the Internet can be considered as
“a source of data about society and culture” [12] at large.
The promise of producing observational data, i.e. data that
documents what people do rather than what they say they
do, without having to manually protocol behavior,
expressions, and interactions is particularly enticing to
researchers. SNS in general, and the gigantic Facebook
platform in particular, can be likened, on a certain level, to
observational devices or even to experimental designs: the
“captured” data are closely related to meticulously
constructed technical and visual forms – functionalities,
interfaces, data structures, and so forth – that function as
“grammars of action” [1], enabling and directing activities
in distinct ways by providing and circumscribing
possibilities for action and expression. Even if the design of
this large-scale social experiment is specified neither by nor
for social scientists and humanists, the delineated and
parametered spaces provided by SNS confer a controlled
frame of reference to gathered data. No wonder that
Cameron Marlow, one of the research scientists working at
Facebook considers the service to be “the world's most
powerful instrument for studying human society” [16]. In
order to better understand how such data can be gathered, a
short overview of existing approaches is indispensable.
Existing Approaches
The already mentioned review paper [19] distinguishes five
categories of empirical Facebook research: descriptive
analysis of users, motivations for using Facebook, identity
presentation, the role of Facebook in social interactions, and
privacy and information disclosure. It is not difficult to see
how approaches gathering data from or through the
platform can be useful for each of these areas of
investigation. The question, then, is what data can actually
be accessed and how this is to be done, considering that the
particular technique chosen has important repercussions for
the scope of what can be realistically acquired.
One can largely distinguish two general orientations when it
comes to collecting digital data from SNS through
software-based tools: first, researchers can recruit
participants, through Facebook itself or from the outside,
and gather data by asking them to fill out questionnaires,
often via so called Facebook applications1
. [11] While this
method certainly differs from traditional ways of recruiting
participants in terms of logistics and sampling procedures,
it is not fundamentally different from online surveying in
general.2 Second, data can be retrieved in various ways
from the pools of information that the Facebook platform
already collects as part of its general operation. This latter
approach, which is the focus of this paper, is fueled by data
derived from both sides of the distinction Schäfer makes
between “implicit and explicit participation” [14], referring
to the difference between information and content
deliberately provided by users, e.g. by filling out their
profiles, and the data collected and produced by logging
users’ actions in sometimes minute detail. While Facebook
members share content, write messages, and curate their
profiles, they also click, watch, read, navigate, and so forth,
thereby providing additional data points that are stored and
analyzed. Because these activities revolve around elements
that have cultural significance – liking a page of a political
party is more than “clicking” – these data are not simply
behavioral, but allow for deeper probing into culture. For
research scholars, there are three ways by which to gain
access to these data, with significant differences between
approaches in terms of technical requirements and
institutional positioning:
Direct database access to the company’s servers is reserved
to in-house researchers or cooperation between a SNS and a
research institution. [17] Certain companies also make data
“donations”, for example Twitter deciding to transfer its
complete archive to the Library of Congress, albeit with a
significant delay. The data made accessible in these ways
are generally very large and well structured, but often
anonymized or aggregated. Partnering with a platform
owner is certainly the only (legal) way to gain access to all
collected data, at least in theory.
Access through sanctioned APIs makes use of the machine
interfaces provided by many Web 2.0 services to third-party
developers with the objective of stimulating application
development and integration with other services in order to
provide additional functionality and utility to users. These
interfaces also provide well-structured data, but are
generally limited in terms of which data, how much data,
and how often data can be retrieved. Conditions can vary
significantly between services: in contrast to Twitter, for
example, Facebook is quite restrictive in terms of what data
can be accessed, but imposes few limits on request
frequency. Companies also retain the right to modify or
close their data interfaces, which can lead to substantial
problems for researchers.

1 A Facebook application is a program that is provided by a
third-party but integrates directly into the platform.
2 One should note that studies using questionnaires on
Facebook often access profile data as well.
User interface crawling can be done manually, but usually
employs so-called bots or spiders that read the HTML
documents used to provide graphical interfaces to users,
either directly at the HTTP protocol level or via browser
automation from the rendered DOM.3 [8] These techniques
can circumvent the limitations of APIs, but often at the
price of technical and legal uncertainties if a platform
provider’s permission is not explicitly granted. In the case
of Facebook, bot detection mechanisms are in place and
suspicious activity can quickly lead to account suspension.
If performed on a large scale, all of these approaches
require either custom programming or considerable
amounts of manual work. The focus points and
requirements for research and teaching do, however, bear
marks of resemblance and Facebook itself is designed
around a limited number of functionalities or “spaces”. One
can therefore argue that general-purpose tools may be
envisioned that provide utility to a variety of research
projects and interests. Several such data extractors
targeting Facebook have been developed over the last years,
invariably using sanctioned APIs for data gathering. These
tools generally export data in common formats and they
focus on specific sections of the platform – partly by
choice, partly due to limitations imposed by the platform
itself. Their goals are also similar: to lower the technical
and logistical requirements for empirical research via data
analysis in order to further the ability of researchers to
study a medium that unites over a billion users in a system
that is essentially conceived as a walled garden. In what
follows, I describe the Netvizz application4
, a tool designed
to help research scholars in extracting data from Facebook.
Similar Work
The enormous success of Facebook has prompted the
emergence of a large number of analytics tools for
marketing purposes, which often focus on pages, the
section of Facebook that brand communication and
consumer relations rely on, due to their public showcase
character. Because these tools are generally built for
monitoring marketing campaigns, they target page owners
rather than researchers interested in studying a page. For
this reasons – and the sheer number of tools available – I
will leave these applications to the side.
There are, however, two tools that function as generalpurpose data extractors for researchers studying Facebook.
NameGenWeb5 originated at the Oxford Internet Institute

3 The latter approach has become more common due to the
fact that sites are increasingly using programming
languages (mostly JavaScript) to assemble pages client-side
rather than sending finished documents described in a
markup language (mostly HTML).
4 https://apps.facebook.com/netvizz/
5 https://apps.facebook.com/namegenweb/
and provides the possibility of exporting a user’s friendship
network, i.e. all of the user’s friends, the friendship
connections between them, and a wide array of variables for
each user account extracted. Another application, the Social
Network Importer
6
, a plug-in for the NodeXL network
analysis and visualization toolkit developed by an
international group of scholars, provides similar
functionality for downloading personal networks, but also a
means to extract extensive data from Facebook pages,
including monopartite7 networks for users and posts, based
on co-like or co-comment activities, and bipartite networks
combining the two in a single graph. One should also
mention Wolfram Alpha’s “Facebook report”8 in this
context: while it does not make raw data available, and
therefore limits in-depth analytics using statistical or graph
theoretical approaches, the tool provides a large number of
analytical views on personal networks.
The Netvizz application provides “raw” data for both
personal networks and pages, but provides data perspectives
not available in other tools, e.g. comment text extraction; it
also provides data for groups, a third functional space on
Facebook. Running as a Web application, Netvizz does not
require the use of Microsoft Excel on Windows like
NodeXL and thereby further lowers the threshold to
engagement with Facebook’s rich data pools. The next
section will introduce the application and its different data
outputs in more detail.